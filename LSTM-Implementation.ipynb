{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1617145456545,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"CeOjVDmlYQgi"},"outputs":[],"source":["#problem statement"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1617145472578,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"KPPwZ8mdYVgj"},"outputs":[],"source":["#generate story similar to alice in wonderland"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3226,"status":"ok","timestamp":1617145514203,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"x6CnfqBRYaTv"},"outputs":[],"source":["import torch\n","import os\n","import torch.nn as nn\n","import numpy as np\n","from torch.nn.utils import clip_grad_norm"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":277,"status":"ok","timestamp":1617145700111,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"E-_JEYMQYjwY"},"outputs":[],"source":["class Dictionary(object):\n","    def __init__(self):\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.idx = 0\n","\n","    def add_word(self, word):\n","        if word not in self.word2idx:\n","            self.word2idx[word] = self.idx\n","            self.idx2word[self.idx] = word\n","            self.idx += 1\n","            \n","    def __len__(self):\n","        return len(self.word2idx)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":303,"status":"ok","timestamp":1617148181443,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"14C1tEzPZR25"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/NN-bootcamp')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":267,"status":"ok","timestamp":1617148183400,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"ExYjAvExZ5wJ","outputId":"0f6ff13c-4d5d-41d0-959a-eb4b5360c2de"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/NN-bootcamp'"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["%pwd"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1617148279799,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"i-lOwlZ5Z92R"},"outputs":[],"source":["class TextProcess(object):\n","    \n","    def __init__(self):\n","        self.dictionary = Dictionary()\n","\n","    def get_data(self, path, batch_size=20):\n","        with open(path, 'r') as f:\n","            tokens = 0\n","            for line in f:\n","                words = line.split() + ['\u003ceos\u003e']\n","                tokens += len(words)\n","                for word in words: \n","                    self.dictionary.add_word(word)  \n","        #Create a 1-D tensor that contains the index of all the words in the file\n","        rep_tensor = torch.LongTensor(tokens)\n","        index = 0\n","        with open(path, 'r') as f:\n","            for line in f:\n","                words = line.split() + ['\u003ceos\u003e']\n","                for word in words:\n","                    rep_tensor[index] = self.dictionary.word2idx[word]\n","                    index += 1\n","        #Find out how many batches we need            \n","        num_batches = rep_tensor.shape[0] // batch_size     \n","        #Remove the remainder (Filter out the ones that don't fit)\n","        rep_tensor = rep_tensor[:num_batches*batch_size]\n","        # return (batch_size,num_batches)\n","        rep_tensor = rep_tensor.view(batch_size, -1)\n","        return rep_tensor"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1617148282442,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"o30VxToYjHqG"},"outputs":[],"source":["embed_size = 128    #Input features to the LSTM\n","hidden_size = 1024  #Number of LSTM units\n","num_layers = 1\n","num_epochs = 20\n","batch_size = 20\n","timesteps = 30\n","learning_rate = 0.002"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1617148367167,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"FGWK845gjaZj","outputId":"0d89881b-e6d1-4051-f61b-5ec3a7e44ba8"},"outputs":[{"name":"stdout","output_type":"stream","text":["basics-pytorch.ipynb  LSTM-Implementation.ipynb\n","cnn.ipynb\t      The-Complete-Neural-Networks-Bootcamp-Theory-Applications\n","FFNN-Diabetes\t      Visualize-NN\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":842,"status":"ok","timestamp":1617148380039,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"m9w6VEXEjISN"},"outputs":[],"source":["corpus=TextProcess()\n","rep_tensor = corpus.get_data('The-Complete-Neural-Networks-Bootcamp-Theory-Applications/alice.txt', batch_size)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1617150393456,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"AXGEgCfLjgAW","outputId":"4ba839f6-1ac8-4993-f323-b1f2105d34c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["5290\n"]}],"source":["vocab_size = len(corpus.dictionary)\n","print(vocab_size)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1617150412196,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"Jj77IZAUrPon","outputId":"c668f61e-1ad9-497c-afde-df648277c577"},"outputs":[{"name":"stdout","output_type":"stream","text":["49\n"]}],"source":["num_batches = rep_tensor.shape[1] // timesteps\n","print(num_batches)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":229,"status":"ok","timestamp":1617150428227,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"ZdfhPtUDjhxO"},"outputs":[],"source":["class TextGenerator(nn.Module):\n","    \n","    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n","        super(TextGenerator, self).__init__()\n","        self.embed = nn.Embedding(vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n","        self.linear = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x, h):\n","        # Perform Word Embedding \n","        x = self.embed(x)\n","        #Reshape the input tensor\n","        #x = x.view(batch_size,timesteps,embed_size)\n","        out, (h, c) = self.lstm(x, h)\n","        # Reshape the output from (samples,timesteps,output_features) to a shape appropriate for the FC layer \n","        # (batch_size*timesteps, hidden_size)\n","        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n","        # Decode hidden states of all time steps\n","        out = self.linear(out)\n","        return out, (h, c)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":466,"status":"ok","timestamp":1617151424710,"user":{"displayName":"Nikhil Dhara Venkata","photoUrl":"","userId":"15085724082298459086"},"user_tz":420},"id":"DE3CCYaFrUM5"},"outputs":[],"source":["model = TextGenerator(vocab_size, embed_size, hidden_size, num_layers)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"j8i4y58_vHao"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/20], Loss: 8.5765\n","Epoch [2/20], Loss: 5.9709\n","Epoch [3/20], Loss: 5.2460\n","Epoch [4/20], Loss: 4.7196\n","Epoch [5/20], Loss: 4.1653\n","Epoch [6/20], Loss: 3.6985\n","Epoch [7/20], Loss: 3.1947\n","Epoch [8/20], Loss: 2.7880\n","Epoch [9/20], Loss: 2.5318\n","Epoch [10/20], Loss: 2.1924\n","Epoch [11/20], Loss: 1.8997\n","Epoch [12/20], Loss: 1.6276\n","Epoch [13/20], Loss: 1.3281\n","Epoch [14/20], Loss: 1.0678\n","Epoch [15/20], Loss: 0.8262\n","Epoch [16/20], Loss: 0.5356\n","Epoch [17/20], Loss: 0.4591\n","Epoch [18/20], Loss: 0.2545\n","Epoch [19/20], Loss: 0.1457\n","Epoch [20/20], Loss: 0.0977\n"]}],"source":["for epoch in range(num_epochs):\n","    # Set initial hidden and cell states\n","    states = (torch.zeros(num_layers, batch_size, hidden_size),\n","              torch.zeros(num_layers, batch_size, hidden_size))\n","\n","    for i in range(0, rep_tensor.size(1) - timesteps, timesteps):\n","        # Get mini-batch inputs and targets\n","        inputs = rep_tensor[:, i:i+timesteps]  \n","        targets = rep_tensor[:, (i+1):(i+1)+timesteps]\n","        \n","        outputs,_ = model(inputs, states)\n","        loss = loss_fn(outputs, targets.reshape(-1))\n","\n","        model.zero_grad()\n","        loss.backward()\n","        #Perform Gradient Clipping. clip_value (float or int) is the maximum allowed value of the gradients \n","        #The gradients are clipped in the range [-clip_value, clip_value]. This is to prevent the exploding gradient problem\n","        clip_grad_norm(model.parameters(), 0.5)\n","        optimizer.step()\n","              \n","        step = (i+1) // timesteps\n","        if step % 100 == 0:\n","            print ('Epoch [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, num_epochs, loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDCBsKLLvg6L"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNFpGaAK7Z/gKTjasdi88H1","mount_file_id":"1sa_irLdj-VEaST5eg96lMFIHQPBDiRsu","name":"LSTM-Implementation.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}